{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Needed to get access to mappening.utils.database since this is under mappening.ml\n",
    "import sys\n",
    "sys.path.insert(0,'./../..')\n",
    "\n",
    "from mappening.utils.secrets import MLAB_USERNAME, MLAB_PASSWORD\n",
    "\n",
    "from pymongo import MongoClient\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "old_mappening_uri = 'mongodb://{0}:{1}@ds044709.mlab.com:44709/mappening_data'.format(MLAB_USERNAME, MLAB_PASSWORD)\n",
    "\n",
    "# Set up database connections\n",
    "events_client = MongoClient(old_mappening_uri)\n",
    "events_db = events_client['mappening_data']\n",
    "events_ml = events_db.events_ml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gatherFreeFoodEvents():\n",
    "    \"\"\"Return panda dataframe of events with category, description, and name\"\"\"\n",
    "    allFreeFoodLabeledEvents = []\n",
    "    allEvents = events_ml.find({}, {\"free_food\": 1, \"description\": 1, \"name\": 1, \"hoster\": 1, \"_id\": 0})\n",
    "    count = 0\n",
    "    for e in allEvents:\n",
    "        count += 1\n",
    "        e['hoster'] = e['hoster']['name']\n",
    "        if 'free_food' in e and 'description' in e and 'name' in e:\n",
    "            allFreeFoodLabeledEvents.append(e)\n",
    "    print count, \"total events, learning from the\", len(allFreeFoodLabeledEvents), \"well labeled events\"\n",
    "    return pd.DataFrame(allFreeFoodLabeledEvents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6936 total events, learning from the 2173 well categorized events\n"
     ]
    }
   ],
   "source": [
    "x = gatherFreeFoodEvents()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda2/envs/ml/lib/python2.7/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('mean_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/anaconda2/envs/ml/lib/python2.7/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('split0_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/anaconda2/envs/ml/lib/python2.7/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('split1_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/anaconda2/envs/ml/lib/python2.7/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('split2_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/anaconda2/envs/ml/lib/python2.7/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('split3_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/anaconda2/envs/ml/lib/python2.7/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('split4_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/anaconda2/envs/ml/lib/python2.7/site-packages/sklearn/utils/deprecation.py:122: FutureWarning: You are accessing a training score ('std_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>params</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>...</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split3_train_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>split4_train_score</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.280723</td>\n",
       "      <td>0.004381</td>\n",
       "      <td>0.870225</td>\n",
       "      <td>0.984698</td>\n",
       "      <td>60</td>\n",
       "      <td>10</td>\n",
       "      <td>{u'n_estimators': 10, u'max_depth': 60}</td>\n",
       "      <td>1</td>\n",
       "      <td>0.855172</td>\n",
       "      <td>0.989068</td>\n",
       "      <td>...</td>\n",
       "      <td>0.882759</td>\n",
       "      <td>0.976985</td>\n",
       "      <td>0.894009</td>\n",
       "      <td>0.992524</td>\n",
       "      <td>0.889401</td>\n",
       "      <td>0.983324</td>\n",
       "      <td>0.008237</td>\n",
       "      <td>0.000235</td>\n",
       "      <td>0.024269</td>\n",
       "      <td>0.005503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.004469</td>\n",
       "      <td>0.013681</td>\n",
       "      <td>0.868845</td>\n",
       "      <td>0.997584</td>\n",
       "      <td>90</td>\n",
       "      <td>30</td>\n",
       "      <td>{u'n_estimators': 30, u'max_depth': 90}</td>\n",
       "      <td>2</td>\n",
       "      <td>0.855172</td>\n",
       "      <td>0.998274</td>\n",
       "      <td>...</td>\n",
       "      <td>0.891954</td>\n",
       "      <td>0.997123</td>\n",
       "      <td>0.882488</td>\n",
       "      <td>0.997700</td>\n",
       "      <td>0.866359</td>\n",
       "      <td>0.997125</td>\n",
       "      <td>0.027720</td>\n",
       "      <td>0.004431</td>\n",
       "      <td>0.016353</td>\n",
       "      <td>0.000430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.383511</td>\n",
       "      <td>0.005493</td>\n",
       "      <td>0.868385</td>\n",
       "      <td>0.991716</td>\n",
       "      <td>90</td>\n",
       "      <td>10</td>\n",
       "      <td>{u'n_estimators': 10, u'max_depth': 90}</td>\n",
       "      <td>3</td>\n",
       "      <td>0.850575</td>\n",
       "      <td>0.993671</td>\n",
       "      <td>...</td>\n",
       "      <td>0.880460</td>\n",
       "      <td>0.990219</td>\n",
       "      <td>0.896313</td>\n",
       "      <td>0.993675</td>\n",
       "      <td>0.873272</td>\n",
       "      <td>0.991374</td>\n",
       "      <td>0.021267</td>\n",
       "      <td>0.000477</td>\n",
       "      <td>0.019981</td>\n",
       "      <td>0.001692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2.039080</td>\n",
       "      <td>0.045554</td>\n",
       "      <td>0.867925</td>\n",
       "      <td>0.998159</td>\n",
       "      <td>90</td>\n",
       "      <td>60</td>\n",
       "      <td>{u'n_estimators': 60, u'max_depth': 90}</td>\n",
       "      <td>4</td>\n",
       "      <td>0.852874</td>\n",
       "      <td>0.997699</td>\n",
       "      <td>...</td>\n",
       "      <td>0.880460</td>\n",
       "      <td>0.998274</td>\n",
       "      <td>0.887097</td>\n",
       "      <td>0.998850</td>\n",
       "      <td>0.877880</td>\n",
       "      <td>0.997700</td>\n",
       "      <td>0.121044</td>\n",
       "      <td>0.042841</td>\n",
       "      <td>0.017637</td>\n",
       "      <td>0.000431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2.194517</td>\n",
       "      <td>0.019347</td>\n",
       "      <td>0.865624</td>\n",
       "      <td>0.998274</td>\n",
       "      <td>None</td>\n",
       "      <td>60</td>\n",
       "      <td>{u'n_estimators': 60, u'max_depth': None}</td>\n",
       "      <td>5</td>\n",
       "      <td>0.841379</td>\n",
       "      <td>0.998274</td>\n",
       "      <td>...</td>\n",
       "      <td>0.896552</td>\n",
       "      <td>0.998274</td>\n",
       "      <td>0.882488</td>\n",
       "      <td>0.998850</td>\n",
       "      <td>0.866359</td>\n",
       "      <td>0.997700</td>\n",
       "      <td>0.314347</td>\n",
       "      <td>0.001805</td>\n",
       "      <td>0.021994</td>\n",
       "      <td>0.000364</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  mean_score_time  mean_test_score  mean_train_score  \\\n",
       "3        0.280723         0.004381         0.870225          0.984698   \n",
       "7        1.004469         0.013681         0.868845          0.997584   \n",
       "6        0.383511         0.005493         0.868385          0.991716   \n",
       "8        2.039080         0.045554         0.867925          0.998159   \n",
       "11       2.194517         0.019347         0.865624          0.998274   \n",
       "\n",
       "   param_max_depth param_n_estimators  \\\n",
       "3               60                 10   \n",
       "7               90                 30   \n",
       "6               90                 10   \n",
       "8               90                 60   \n",
       "11            None                 60   \n",
       "\n",
       "                                       params  rank_test_score  \\\n",
       "3     {u'n_estimators': 10, u'max_depth': 60}                1   \n",
       "7     {u'n_estimators': 30, u'max_depth': 90}                2   \n",
       "6     {u'n_estimators': 10, u'max_depth': 90}                3   \n",
       "8     {u'n_estimators': 60, u'max_depth': 90}                4   \n",
       "11  {u'n_estimators': 60, u'max_depth': None}                5   \n",
       "\n",
       "    split0_test_score  split0_train_score       ...         split2_test_score  \\\n",
       "3            0.855172            0.989068       ...                  0.882759   \n",
       "7            0.855172            0.998274       ...                  0.891954   \n",
       "6            0.850575            0.993671       ...                  0.880460   \n",
       "8            0.852874            0.997699       ...                  0.880460   \n",
       "11           0.841379            0.998274       ...                  0.896552   \n",
       "\n",
       "    split2_train_score  split3_test_score  split3_train_score  \\\n",
       "3             0.976985           0.894009            0.992524   \n",
       "7             0.997123           0.882488            0.997700   \n",
       "6             0.990219           0.896313            0.993675   \n",
       "8             0.998274           0.887097            0.998850   \n",
       "11            0.998274           0.882488            0.998850   \n",
       "\n",
       "    split4_test_score  split4_train_score  std_fit_time  std_score_time  \\\n",
       "3            0.889401            0.983324      0.008237        0.000235   \n",
       "7            0.866359            0.997125      0.027720        0.004431   \n",
       "6            0.873272            0.991374      0.021267        0.000477   \n",
       "8            0.877880            0.997700      0.121044        0.042841   \n",
       "11           0.866359            0.997700      0.314347        0.001805   \n",
       "\n",
       "    std_test_score  std_train_score  \n",
       "3         0.024269         0.005503  \n",
       "7         0.016353         0.000430  \n",
       "6         0.019981         0.001692  \n",
       "8         0.017637         0.000431  \n",
       "11        0.021994         0.000364  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from scipy.sparse import hstack\n",
    "\n",
    "# create the transform\n",
    "vectorizer = TfidfVectorizer(stop_words='english')\n",
    "\n",
    "# tokenize and build vocab\n",
    "X_name_transform = vectorizer.fit_transform(X['name'])\n",
    "X_details_transform = vectorizer.fit_transform(X['description'])\n",
    "X_total_transform = hstack([X_name_transform, X_details_transform])\n",
    "\n",
    "rf = RandomForestClassifier()\n",
    "param = {'n_estimators': [10, 30, 60],\n",
    "          'max_depth': [30,60,90, None]}\n",
    "gs = GridSearchCV(rf, param, cv=5, n_jobs=-1)\n",
    "gs.fit(X_total_transform, X['free_food'])\n",
    "pd.DataFrame(gs.cv_results_).sort_values('mean_test_score', ascending=False)[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=60, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from scipy.sparse import hstack\n",
    "\n",
    "# create the transform\n",
    "nameVectorizer = TfidfVectorizer(stop_words='english')\n",
    "detailVectorizer = TfidfVectorizer(stop_words='english')\n",
    "\n",
    "# tokenize and build vocab\n",
    "X_name_transform = nameVectorizer.fit_transform(X['name'])\n",
    "X_details_transform = detailVectorizer.fit_transform(X['description'])\n",
    "X_total_transform = hstack([X_name_transform, X_details_transform])\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=10, max_depth=60)\n",
    "rf.fit(X_total_transform, X['free_food'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predictFoodProbability(nameVectorizer, detailVectorizer, classifier, X, threshold=.1):\n",
    "    \"\"\"\n",
    "    :param nameVectorizer: TfidfVectorizer for the event names\n",
    "    :param detailVectorizer: TfidfVectorizer for details\n",
    "    :param classifer: scikit classifer with predict probability function(e.g RandomForestClassifier)\n",
    "    :param X: pandas dataframe with 'name' and 'description' columns\n",
    "    :param threshold: probabilty threshold for classifer prediction(note depending on classifer p varies)\n",
    "\n",
    "    Returns parallel list of categories\n",
    "    \"\"\"\n",
    "\n",
    "    X_name_transform = nameVectorizer.transform(X['name'])\n",
    "    X_details_transform = detailVectorizer.transform(X['description'])\n",
    "    X_total_transform = hstack([X_name_transform, X_details_transform])\n",
    "    y_pred = classifier.predict(X_total_transform)\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44\n",
      "False\n",
      "                                          description  free_food  \\\n",
      "44  On Tuesday, join Bruins for Israel as we explo...       True   \n",
      "\n",
      "               hoster         name  \n",
      "44  Bruins for Israel  Israel 360°  \n",
      "[u\"On Tuesday, join Bruins for Israel as we explore some complex legal and geopolitical topics related to Israel. Be ready to expose yourself to new perspectives, and empathize with viewpoints that you may not have before.\\n\\nIf you have ever wondered about the nuances and intricacies of the Israeli political landscape,  or thought that you could use a fresh perspective on the country\\u2019s issues, then this is just the program for you!  \\n\\nThere will be delicious sushi, inquisitive students, and a desire for learning and appreciating new ideas. The more the merrier! See you there.\\n\\nRight after we invite you to stay for Hillel's Taco (Giving) Tuesday Phone-a-thon!\"]\n"
     ]
    }
   ],
   "source": [
    "def findFirstIncorrectModel(nameVectorizer, detailVectorizer, X, rf):\n",
    "    y_pred = predictFoodProbability(nameVectorizer, detailVectorizer, rf, X)\n",
    "    for i in range(len(X)-1):\n",
    "        if y_pred[i] != list(X[i:i+1]['free_food'])[0]:\n",
    "            print i\n",
    "            print y_pred[i]\n",
    "            print X[i:i+1]\n",
    "            print list(X[i:i+1]['description'])\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2173"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def trainModels():\n",
    "    X = gatherFreeFoodEvents()\n",
    "\n",
    "    # create the transform\n",
    "    nameVectorizer = TfidfVectorizer(stop_words='english')\n",
    "    detailVectorizer = TfidfVectorizer(stop_words='english')\n",
    "\n",
    "    # tokenize and build vocab on name and description seperately\n",
    "    X_name_transform = nameVectorizer.fit_transform(X['name'])\n",
    "    X_details_transform = detailVectorizer.fit_transform(X['description'])\n",
    "    #TODO: Learn on hoster details too\n",
    "    X_total_transform = hstack([X_name_transform, X_details_transform])\n",
    "\n",
    "    # train model\n",
    "    rf = RandomForestClassifier(n_estimators=10, max_depth=60)\n",
    "    rf.fit(X_total_transform, X['free_food'])\n",
    "\n",
    "    #save model\n",
    "    with open(r\"freeFoodModel.pickle\", \"wb\") as output_file:\n",
    "        pickle.dump(rf, output_file)\n",
    "\n",
    "    with open(r\"nameVectorizer.pickle\", \"wb\") as output_file:\n",
    "        pickle.dump(nameVectorizer, output_file)\n",
    "\n",
    "    with open(r\"detailVectorizer.pickle\", \"wb\") as output_file:\n",
    "        pickle.dump(detailVectorizer, output_file)\n",
    "\n",
    "    print(\"Successfully trained and saved categorization models\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ml]",
   "language": "python",
   "name": "conda-env-ml-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
